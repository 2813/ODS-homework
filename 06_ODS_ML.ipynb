{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2813/ODS-homework/blob/main/06_ODS_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ff2633b",
      "metadata": {
        "id": "6ff2633b"
      },
      "source": [
        "# **Градиентный бустинг**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ad88cef",
      "metadata": {
        "id": "6ad88cef"
      },
      "source": [
        "## **Подготовка для работы в Google Colab или Kaggle**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6afda6b",
      "metadata": {
        "id": "e6afda6b"
      },
      "source": [
        "#### Код для подключения Google Drive в Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb2bfe83",
      "metadata": {
        "id": "cb2bfe83"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0e04abc",
      "metadata": {
        "id": "f0e04abc"
      },
      "source": [
        "#### Код для получения пути к файлам в Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48756f3c",
      "metadata": {
        "id": "48756f3c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cec6748e",
      "metadata": {
        "id": "cec6748e"
      },
      "source": [
        "#### Код для установки библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b3f5bda",
      "metadata": {
        "id": "2b3f5bda"
      },
      "outputs": [],
      "source": [
        "%pip install numpy==1.26.4 pandas==2.1.4 scikit-learn==1.7.0 matplotlib==3.8.0 seaborn==0.13.2 catboost==1.2.8 lightgbm==4.6.0 xgboost==3.0.2 optuna==4.4.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5884a024",
      "metadata": {
        "id": "5884a024"
      },
      "source": [
        "## **Важная информация**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed3ee903",
      "metadata": {
        "id": "ed3ee903"
      },
      "source": [
        "**Для правильного воспроизведения результатов** решения задач:\n",
        "\n",
        "* Рекомендуется придерживаться имеющего в заданиях кода в исходной последовательности. Для этого при решении задач **восстановите недостающие фрагменты кода, которые отмечены символом** `...` (Ellipsis).\n",
        "\n",
        "* Если класс, функция или метод предусматривает параметр random_state, всегда указывайте **random_state=RANDOM_STATE**.\n",
        "\n",
        "* Для всех параметров (кроме random_state) класса, функции или метода **используйте значения по умолчанию, если иное не указано в задании**.\n",
        "\n",
        "**Если скорость обучения слишком низкая**, рекомендуется следующее:\n",
        "\n",
        "* В модели или/и GridSearchCV поменяйте значение параметра n_jobs, который отвечает за параллелизм вычислений.\n",
        "\n",
        "* Воспользуйтесь вычислительными ресурсами Google Colab или Kaggle.\n",
        "\n",
        "***Использовать GPU не рекомендуется, поскольку результаты обучения некоторых моделей могут отличаться на CPU и GPU.***\n",
        "\n",
        "После выполнения каждого задания **ответьте на вопросы в тесте.**\n",
        "\n",
        "**ВНИМАНИЕ:** **После каждого нового запуска ноутбука** перед тем, как приступить к выполнению заданий, проверьте настройку виртуального окружения, выполнив код в ячейке ниже."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d7862ed",
      "metadata": {
        "id": "0d7862ed"
      },
      "outputs": [],
      "source": [
        "# Код для проверки настройки виртуального окружения\n",
        "\n",
        "import sys\n",
        "from importlib.metadata import version\n",
        "\n",
        "required = {\n",
        "    'python': '3.11.x',\n",
        "    'numpy': '1.26.4',\n",
        "    'pandas': '2.1.4',\n",
        "    'scikit-learn': '1.7.0',\n",
        "    'matplotlib': '3.8.0',\n",
        "    'seaborn': '0.13.2',\n",
        "    'catboost': '1.2.8',\n",
        "    'lightgbm': '4.6.0',\n",
        "    'xgboost': '3.0.2',\n",
        "    'optuna': '4.4.0'\n",
        "}\n",
        "\n",
        "print(f'{\"Компонент\":<15} | {\"Требуется\":<12} | {\"Установлено\":<12} | {\"Соответствие\"}')\n",
        "print('-' * 62)\n",
        "\n",
        "environment_ok = True\n",
        "for lib, req_ver in required.items():\n",
        "    try:\n",
        "        if lib == 'python':\n",
        "            inst_ver = sys.version.split()[0]\n",
        "            status = '✓' if sys.version_info.major == 3 and sys.version_info.minor == 11 else f'x (требуется {req_ver})'\n",
        "        else:\n",
        "            inst_ver = version(lib)\n",
        "            if inst_ver == req_ver:\n",
        "                status = '✓'\n",
        "            else:\n",
        "                environment_ok = False\n",
        "                status = f'x (требуется {req_ver})'\n",
        "    except:\n",
        "        environment_ok = False\n",
        "        inst_ver = '-'\n",
        "        status = 'x (не установлена)'\n",
        "    print(f'{lib:<15} | {req_ver:<12} | {inst_ver:<12} | {status:<12}')\n",
        "\n",
        "print('\\nРезультат проверки: ',\n",
        "      '✓\\nВсе версии соответствуют требованиям'\n",
        "      if environment_ok else\n",
        "      'x\\nВНИМАНИЕ: Версии некоторых компонентов не соответствуют требованиям!\\n'\n",
        "      'Для решения проблемы обратитесь к инструкции по настройке виртуального окружения')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b421104b",
      "metadata": {
        "id": "b421104b"
      },
      "source": [
        "## **Импорт библиотек и вспомогательные функции**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5d1105d",
      "metadata": {
        "id": "d5d1105d"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1280e07",
      "metadata": {
        "id": "f1280e07"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error, classification_report, roc_auc_score, accuracy_score, f1_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "import optuna\n",
        "from optuna.importance import get_param_importances\n",
        "from optuna.samplers import TPESampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c62ce5fc",
      "metadata": {
        "id": "c62ce5fc"
      },
      "outputs": [],
      "source": [
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e4b0562",
      "metadata": {
        "id": "5e4b0562"
      },
      "source": [
        "## **Практическая часть**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d54af69a",
      "metadata": {
        "id": "d54af69a"
      },
      "source": [
        "### **Градиентный бустинг**\n",
        "\n",
        "Градиентный бустинг (Gradient Boosting) — это метод машинного обучения, основанный на ансамбле слабых моделей, которые последовательно улучшают предсказания друг друга. В отличие от случайного леса, где деревья строятся независимо, в градиентном бустинге над решающими деревьями каждое новое дерево обучается на ошибках предыдущих.\n",
        "\n",
        "**Алгоритм обучения:**\n",
        "\n",
        "1. Инициализируется начальное предсказание $f_{0}(X)$, где $X$ — матрица признаков. Например:\n",
        "\n",
        "    * Метка наиболее популярного класса (для задач классификации).\n",
        "\n",
        "    * Среднее значение или ноль (для задач регрессии).\n",
        "\n",
        "2. Для каждой итерации обучения $t=1,...,T$:\n",
        "\n",
        "    1. Вычисляются остатки (градиент ошибки): $r_{t}=y-f_{t-1}(X)$, где $y$ — истинные значения целевой переменной.\n",
        "\n",
        "    2. Обучается дерево решений $h_{t}(X)$​ для предсказания остатков $r_{t}$.\n",
        "\n",
        "    3. Модель обновляется: $f_{t}(X)=f_{t-1}(X)+\\gamma h_{t}(X)$, где $\\gamma$ — темп (шаг) обучения.\n",
        "\n",
        "Подробнее можно изучить по **ссылкам:**\n",
        "\n",
        "* [Градиентный бустинг | education.yandex.ru](https://education.yandex.ru/handbook/ml/article/gradientnyj-busting)\n",
        "\n",
        "* [All You Need to Know about Gradient Boosting Algorithm − Part 1. Regression | medium.com](https://medium.com/data-science/all-you-need-to-know-about-gradient-boosting-algorithm-part-1-regression-2520a34a502)\n",
        "\n",
        "* [All You Need to Know about Gradient Boosting Algorithm − Part 2. Classification | towardsdatascience.com](https://medium.com/p/d3ed8f56541e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42bfb574",
      "metadata": {
        "id": "42bfb574"
      },
      "source": [
        "### ***Задание 1***\n",
        "\n",
        "Сгенерируйте простой набор данных для регрессии с одной объясняющей переменной (см. код):\n",
        "\n",
        "* `y_true` — истинные значения целевой переменной.\n",
        "\n",
        "* `y` — \"зашумленные\" значения целевой переменной.\n",
        "\n",
        "На сгенерированной выборке обучите 10 деревьев решений DecisionTreeRegressor со значениями параметра **max_depth от 1 до 10**.\n",
        "\n",
        "Для каждого обученного дерева рассчитайте MSE на `y` и `y_true`, постройте график предсказаний.\n",
        "\n",
        "Дополните класс CustomGradientBoostingRegressor, добавив недостающий код там, где это необходимо (**в качестве начального значения используйте среднее**).\n",
        "\n",
        "Обучите модель `gb_reg_def` (CustomGradientBoostingRegressor) **c параметрами по умолчанию**: n_estimators=100, learning_rate=0.1, max_depth=1.\n",
        "\n",
        "Выполните подбор оптимальных гиперпараметров для кастомного класса CustomGradientBoostingRegressor с помощью GridSearchCV (см. замечание ниже).\n",
        "\n",
        "Обучите модель `gb_reg` (CustomGradientBoostingRegressor) с оптимальными гиперпараметрами на полной выборке.\n",
        "\n",
        "Сравните результаты обучения деревьев с разной глубиной (DecisionTreeRegressor) и моделей `gb_reg_def` и `gb_reg`, рассчитав MSE на `y` и `y_true`, а также построив графики предсказаний для каждой из моделей.\n",
        "\n",
        "*Класс CustomGradientBoostingRegressor **наследует от класса BaseEstimator**. Класс BaseEstimator в sklearn является базовым классом, предоставляющим встроенные реализации ключевых методов для оптимизации, кросс-валидации и автоматического конфигурирования моделей в рамках библиотеки sklearn. Это позволяет, например, выполнять оптимизацию гипермараметров моделей кастомного (пользовательского) класса CustomGradientBoostingRegressor с помощью GridSearchCV, если в кастомном классе присутствует реализация методов fit, predict и scoring.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a38527d-8828-4a2f-810b-cd7ab2d4b434",
      "metadata": {
        "id": "6a38527d-8828-4a2f-810b-cd7ab2d4b434"
      },
      "outputs": [],
      "source": [
        "# Сгенерируйте простой набор данных для регрессии\n",
        "\n",
        "rng = np.random.RandomState(RANDOM_STATE)\n",
        "noise = rng.normal(0, 0.18, 1000)\n",
        "X = pd.DataFrame({'x': np.linspace(1, 10, 1000)})\n",
        "y_true = -0.3 * X['x'] ** 0.5 * np.cos(np.pi * X['x'] / 4)\n",
        "y_true = np.array(y_true)\n",
        "y = y_true + noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f176ea3d-804a-48bb-8610-56ec07a308b6",
      "metadata": {
        "id": "f176ea3d-804a-48bb-8610-56ec07a308b6"
      },
      "outputs": [],
      "source": [
        "# Постройте график y и y_true\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(X['x'], y, marker='.', c='#97BFB4', label='y')\n",
        "plt.plot(X['x'], y_true, c='#DD4A48', label='y true')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "094cd411",
      "metadata": {
        "id": "094cd411"
      },
      "outputs": [],
      "source": [
        "# Обучите 10 деревьев DecisionTreeRegressor со значениями параметра max_depth от 1 до 10\n",
        "# Для каждого дерева рассчитайте MSE на y и y_true, постройте график предсказаний\n",
        "# Не забудьте зафиксировать RANDOM_STATE\n",
        "\n",
        "for i in range(1, 11):\n",
        "    tree_reg_i = ...\n",
        "    y_pred_tree_reg_i = ...\n",
        "    mse = mean_squared_error(...)\n",
        "    mse_true = mean_squared_error(...)\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.title(f'Depth: {i}')\n",
        "    plt.scatter(X['x'], y, marker='.', c='#97BFB4', label='y')\n",
        "    plt.plot(X['x'], y_true, c='#DD4A48', label='y true')\n",
        "    plt.plot(X['x'], y_pred_tree_reg_i, c='#4F091D',\n",
        "             label=f'tree({i}) prediction (MSE={...:.4f}, true MSE={...:.4f})')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eea9d61f",
      "metadata": {
        "id": "eea9d61f"
      },
      "outputs": [],
      "source": [
        "# Дополните класс CustomGradientBoostingRegressor\n",
        "# Код метода score изменять не нужно\n",
        "# Не забудьте фиксировать random_state, где это возможно\n",
        "\n",
        "class CustomGradientBoostingRegressor(BaseEstimator):\n",
        "    \"\"\"\n",
        "    Простой регрессор на основе градиентного бустинга над деревьями решений.\n",
        "\n",
        "    Аргументы:\n",
        "        n_estimators (int): Количество деревьев (итераций бустинга). По умолчанию — 100.\n",
        "        learning_rate (float) Темп обучения (шаг градиентного спуска). По умолчанию — 0.1.\n",
        "        max_depth (int): Максимальная глубина дерева бустинга. По умолчанию — 1.\n",
        "        random_state : (int|None): Сид для фиксирования случайного состояния. По умолчанию — None (не фиксировать).\n",
        "\n",
        "    Атрибуты:\n",
        "        f0 (float): Начальное предсказание (среднее значение целевой переменной).\n",
        "        models (list[DecisionTreeRegressor]): Последовательность деревьев, составляющих модель градиентного бустинга.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=1, random_state=None):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_depth = max_depth\n",
        "        self.random_state = random_state\n",
        "        self.f0 = None\n",
        "        self.models = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Обучает модель градиентного бустинга.\n",
        "\n",
        "        Аргументы:\n",
        "            X (pandas.DataFrame): Таблица с признаками.\n",
        "            y (numpy.ndarray): Массив значений целевой переменной.\n",
        "\n",
        "        Возвращает:\n",
        "            CustomGradientBoostingRegressor: Обученная модель градиентного бустинга.\n",
        "        \"\"\"\n",
        "        self.f0 = ...\n",
        "        y_pred = np.full_like(y, self.f0)\n",
        "        for _ in range(self.n_estimators):\n",
        "            residuals = ...\n",
        "            tree = DecisionTreeRegressor(...)\n",
        "            y_pred += ...\n",
        "            self.models.append(tree)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Предсказывает значения целевой переменной.\n",
        "\n",
        "        Аргументы:\n",
        "            X (pandas.DataFrame): Таблица с признаками.\n",
        "\n",
        "        Возвращает:\n",
        "            numpy.ndarray: Массив предсказанных значений целевой переменной.\n",
        "        \"\"\"\n",
        "        y_pred = np.full(X.shape[0], self.f0)\n",
        "        for model in self.models:\n",
        "            y_pred += ...\n",
        "        return y_pred\n",
        "\n",
        "    def score(self, X, y):\n",
        "        \"\"\"\n",
        "        Вычисляет отрицательное значение MSE (Negative MSE) для прогноза.\n",
        "        Метод необходим для применения GridSearchCV.\n",
        "\n",
        "        Аргументы:\n",
        "            X (pandas.DataFrame): Таблица с признаками.\n",
        "            y (numpy.ndarray): Массив значений целевой переменной.\n",
        "\n",
        "        Возвращает:\n",
        "            float: Значение Negative MSE.\n",
        "        \"\"\"\n",
        "        return -mean_squared_error(y, self.predict(X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fafde13a",
      "metadata": {
        "id": "fafde13a"
      },
      "outputs": [],
      "source": [
        "# Обучите модель gb_reg_def (CustomBoostRegressor c параметрами по умолчанию)\n",
        "# Не забудьте зафиксировать RANDOM_STATE\n",
        "\n",
        "gb_reg_def = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be2d3be4",
      "metadata": {
        "id": "be2d3be4"
      },
      "outputs": [],
      "source": [
        "# Для модели gb_reg_def посчитайте MSE на y и y_true, постройте график предсказаний\n",
        "\n",
        "y_pred_gb_reg_def = ...\n",
        "mse_gb_reg_def = ...\n",
        "mse_true_gb_reg_def = ...\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(X['x'], y, marker='.', c='#97BFB4', label='y')\n",
        "plt.plot(X['x'], y_true, c='#DD4A48', label='y true')\n",
        "plt.plot(X['x'], y_pred_gb_reg_def, c='#4F091D',\n",
        "         label=f'CustomGradientBoostingRegressor prediction (MSE={...:.4f}, true MSE={...:.4f})')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "772230c7",
      "metadata": {
        "id": "772230c7"
      },
      "outputs": [],
      "source": [
        "# Подберите оптимальные гиперпараметры для кастомного класса CustomGradientBoostingRegressor с помощью GridSearchCV\n",
        "# Не забудьте зафиксировать RANDOM_STATE\n",
        "\n",
        "params = {\n",
        "    'n_estimators': [100, 150, 200, 250],\n",
        "    'learning_rate': [0.1, 0.2, 0.3, 0.4],\n",
        "    'max_depth': [1, 2, 3]\n",
        "}\n",
        "cv = 5\n",
        "\n",
        "cv_gb_reg = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8234a653",
      "metadata": {
        "id": "8234a653"
      },
      "outputs": [],
      "source": [
        "# Выведите оптимальные гиперпараметры по результатам оптимизации\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6d16ac7",
      "metadata": {
        "id": "f6d16ac7"
      },
      "outputs": [],
      "source": [
        "# Обучите модель gb_reg (CustomBoostRegressor) с оптимальными гиперпараметрами\n",
        "# Не забудьте зафиксировать RANDOM_STATE\n",
        "\n",
        "gb_reg = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5X4xt70NNEKr"
      },
      "outputs": [],
      "source": [
        "# Для модели gb_reg посчитайте MSE на y и y_true, постройте график предсказаний\n",
        "\n",
        "y_pred_gb_reg = ...\n",
        "mse_gb_reg = ...\n",
        "mse_true_gb_reg= ...\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(X['x'], y, marker='.', c='#97BFB4', label='y')\n",
        "plt.plot(X['x'], y_true, c='#DD4A48', label='y true')\n",
        "plt.plot(X['x'], y_pred_gb_reg, c='#4F091D',\n",
        "         label=f'CustomGradientBoostingRegressor prediction (MSE={...:.4f}, true MSE={...:.4f})')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "5X4xt70NNEKr"
    },
    {
      "cell_type": "markdown",
      "id": "05eb3f0f",
      "metadata": {
        "id": "05eb3f0f"
      },
      "source": [
        "### **XGBoost, LightGBM и CatBoost**\n",
        "\n",
        "Среди существующих реализаций градиентного бустинга выделяются три наиболее эффективных и популярных алгоритма: XGBoost, LightGBM и CatBoost.\n",
        "\n",
        "* Extreme Gradient Boosting ([XGBoost](https://xgboost.readthedocs.io/en/latest/), DMLC 2014 г.) — эффективный и гибкий алгоритм градиентного бустинга с поддержкой регуляризации и параллельного обучения, обеспечивающий высокую производительность и универсальность. Алгоритм требует предварительной обработки категориальных признаков (например, One-Hot кодирование).\n",
        "\n",
        "* Light Gradient-Boosting Machine ([LightGBM](https://lightgbm.readthedocs.io/en/latest/), Microsoft 2016 г.) — алгоритм, который выделяется высокой скоростью обучения и масштабируемостью для больших объёмов данных и многомерных признаков. Алгоритм требует предварительной обработки категориальных признаков.\n",
        "\n",
        "\n",
        "* Category Boosting ([CatBoost](https://catboost.ai/), Яндекс 2017 г.) — алгоритм, который специализируется на эффективной работе с категориальными признаками и обладает устойчивостью к переобучению благодаря симметричной структуре деревьев. Алгоритм не требует предварительной обработки категориальных признаков — реализована автоматическая обработка категориальных признаков.\n",
        "\n",
        "Подробнее про эти алгоритмы можно почитать по **ссылкам**:\n",
        "\n",
        "* [XGBoost, LightGBM или CatBoost - какой алгоритм бустинга следует использовать? | vk.com](https://vk.com/@coeusds-xgboost-lightgbm-ili-catboost-kakoi-algoritm-bustinga-sled)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c491f635",
      "metadata": {
        "id": "c491f635"
      },
      "source": [
        "### **Датасет *Employee dataset***\n",
        "\n",
        "**Для решения задания 2 рассмотрим датасет [Employee dataset](https://www.kaggle.com/datasets/tawfikelmetwally/employee-dataset).**\n",
        "\n",
        "Набор данных предназначен для анализа факторов, влияющих на увольнение сотрудников.\n",
        "\n",
        "Целевая переменная — LeaveOrNot:\n",
        "\n",
        "* 1 — сотрудник уволился.\n",
        "\n",
        "* 0 — сотрудник продолжает работать.\n",
        "\n",
        "Датасет включает в себя признаки:\n",
        "\n",
        "* Education — уровень образования.\n",
        "\n",
        "* JoiningYear — год принятия на работу.\n",
        "\n",
        "* City — город, в котором расположен офис сотрудника.\n",
        "\n",
        "* PaymentTier — уровень заработной платы (категория).\n",
        "\n",
        "* Age — возраст.\n",
        "\n",
        "* Gender — пол.\n",
        "\n",
        "* EverBenched — был ли сотрудник когда-либо \"на скамейке запасных\" (не задействован в проектах компании).\n",
        "\n",
        "* ExperienceInCurrentDomain — опыт работы в текущей должности (в годах)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b949c743",
      "metadata": {
        "id": "b949c743"
      },
      "source": [
        "### ***Задание 2***\n",
        "\n",
        "Выполните предобработку датасета (см. код) и убедитесь, что по результатам предобработки:\n",
        "\n",
        "* Датасет разделён на обучающую и тестовую выборки со стратификацией по целевой переменной в соотношении: **train — 75%, test — 25%**.\n",
        "\n",
        "* Имеются два набора датасетов с признаками:\n",
        "\n",
        "    * `X_empl_train`, `X_empl_test` — датасеты **без применения One-Hot кодирования**. Используйте для обучения и оценки **модели `catb_empl` (CatBoostClassifier)**.\n",
        "\n",
        "    * `X_empl_train_onehot`, `X_empl_test_onehot` — датасеты **с применением One-Hot кодирования**. Используйте для обучения и оценки **всех моделей, кроме `catb_empl`**.\n",
        "\n",
        "С помощью **RandomizedSearchCV** (n_iter=50) выполните поиск оптимальных гиперпараметров (для каждой из модели в одельности), и на оптимальном наборе параметров обучите модели:\n",
        "\n",
        "* `rf_empl` — случайный лес (RandomForestClassifier). Подбор параметров и обучение на `X_empl_train_onehot`.\n",
        "\n",
        "* `gb_empl` — градиентный бустинг sklearn (GradientBoostingClassifier). Подбор параметров и обучение на `X_empl_train_onehot`.\n",
        "\n",
        "* `xgb_empl` — модель XGBoost (XGBClassifier). Подбор параметров и обучение на `X_empl_train_onehot`.\n",
        "\n",
        "* `lgbm_empl` — модель LightGBM (LGBMClassifier). Подбор параметров и обучение на `X_empl_train_onehot`.\n",
        "\n",
        "* `catb_empl` — модель CatBoost (CatBoostClassifier). **Подбор параметров и обучение на `X_empl_train`**.\n",
        "\n",
        "Сравните качество прогноза моделей, рассчитав метрики AUC и f1 на тестовых выборках (`X_empl_test` и `X_empl_test_onehot`).\n",
        "\n",
        "*На практике количество итераций при оптимизации гиперпараметров с помощью RandomizedSearchCV зависит от сложности модели и размера датасета. Для реальных задач 50 итераций, вероятнее всего, будет недостаточно. В рамках данного задания небольшое число итераций используется для экономии времени.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2219a46f",
      "metadata": {
        "id": "2219a46f"
      },
      "outputs": [],
      "source": [
        "# Считайте набор данных\n",
        "\n",
        "df_empl = pd.read_csv('employee.csv')\n",
        "df_empl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d935c99c",
      "metadata": {
        "id": "d935c99c"
      },
      "outputs": [],
      "source": [
        "# Информация о типах столбцов в датасете\n",
        "\n",
        "df_empl.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68b78ff3",
      "metadata": {
        "id": "68b78ff3"
      },
      "outputs": [],
      "source": [
        "# Количество уникальных значений в каждом из столбцов датасета\n",
        "\n",
        "df_empl.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "268ff44b",
      "metadata": {
        "id": "268ff44b"
      },
      "outputs": [],
      "source": [
        "# Создайте список категориальных переменных (не включая целевую переменную)\n",
        "\n",
        "empl_cat_feat = ['Education', 'City', 'PaymentTier', 'Gender', 'EverBenched']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb9dec06",
      "metadata": {
        "id": "eb9dec06"
      },
      "outputs": [],
      "source": [
        "# Выделите объясняемый фактор в отдельную переменную\n",
        "\n",
        "X_empl, y_empl = df_empl.drop(columns=['LeaveOrNot']), df_empl['LeaveOrNot']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "835c703b",
      "metadata": {
        "id": "835c703b"
      },
      "outputs": [],
      "source": [
        "# Разделите датасет на обучающую (75%) и тестовую (25%) выборки со стратификацией по целевой переменной\n",
        "# Напоминание: не забудьте про RANDOM_STATE\n",
        "\n",
        "X_empl_train, X_empl_test, y_empl_train, y_empl_test = ... # 75/25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "782e8032",
      "metadata": {
        "id": "782e8032"
      },
      "outputs": [],
      "source": [
        "# Закодируйте категориальные признаки числами 0 и 1 с помощью OneHotEncoder\n",
        "# Выделите отдельные датасеты с закодированными признаками\n",
        "#   train -> fit_transform\n",
        "#   test -> transform\n",
        "\n",
        "empl_encoder = OneHotEncoder(sparse_output=False, drop='first').set_output(transform='pandas')\n",
        "\n",
        "X_empl_train_onehot = ...\n",
        "X_empl_test_onehot = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35bbb209",
      "metadata": {
        "id": "35bbb209"
      },
      "outputs": [],
      "source": [
        "# Сформируем таблицу для сравнения качества прогноза моделей на тестовой выборке\n",
        "\n",
        "empl_results = pd.DataFrame({\n",
        "    'model': ['rf_empl', 'gb_empl', 'xgb_empl', 'lgbm_empl', 'catb_empl'],\n",
        "    'auc_roc': np.zeros(5),\n",
        "    'f1': np.zeros(5)\n",
        "})\n",
        "empl_results = empl_results.set_index('model', drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7c57c38",
      "metadata": {
        "id": "f7c57c38"
      },
      "source": [
        "##### `rf_empl` (RandomForestClassifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84772ac6",
      "metadata": {
        "id": "84772ac6"
      },
      "outputs": [],
      "source": [
        "# Подберите оптимальные гиперпараметры обучения rf_empl с помощью RandomizedSearchCV\n",
        "# Не забудьте зафиксировать RANDOM_STATE\n",
        "\n",
        "estimator = ...\n",
        "params = {\n",
        "    'max_depth': range(1, 11),\n",
        "    'n_estimators': range(50, 300)\n",
        "}\n",
        "n_iter = 50\n",
        "scoring = 'roc_auc'\n",
        "cv = 5\n",
        "\n",
        "rf_empl = RandomizedSearchCV(\n",
        "    ...\n",
        "    random_state=...,\n",
        "    n_jobs=-1, # Может ускорить вычисления за счёт параллелизма, не влияет на результат\n",
        "    refit=True # Переобучает модель на всей выборке после подбора гиперпараметров (по умолчанию True, можно не указывать)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cdf5aef",
      "metadata": {
        "id": "8cdf5aef"
      },
      "outputs": [],
      "source": [
        "# Результат подбора гиперпараметров для rf_empl\n",
        "\n",
        "print(f'Итерация: {...}')\n",
        "print(f'AUC: {...:.4f}')\n",
        "print(f'Параметры: {...}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ad08b95",
      "metadata": {
        "id": "8ad08b95"
      },
      "outputs": [],
      "source": [
        "# Средняя продолжительность обучения rf_empl (сек.)\n",
        "\n",
        "print('{:.4f}'.format(rf_empl.cv_results_['mean_fit_time'].mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d977be8",
      "metadata": {
        "id": "7d977be8"
      },
      "outputs": [],
      "source": [
        "# На тестовой выборке оцените AUC и f1 для модели rf_empl\n",
        "# Добавьте результат в empl_results\n",
        "\n",
        "empl_results.loc['rf_empl', 'auc_roc'] = ...\n",
        "empl_results.loc['rf_empl', 'f1'] = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c737b46f",
      "metadata": {
        "id": "c737b46f"
      },
      "source": [
        "##### `gb_empl` (GradientBoostingClassifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "558b7c6c",
      "metadata": {
        "id": "558b7c6c"
      },
      "outputs": [],
      "source": [
        "# Подберите оптимальные гиперпараметры обучения gb_empl с помощью RandomizedSearchCV\n",
        "# Не забудьте зафиксировать RANDOM_STATE\n",
        "\n",
        "estimator = ...\n",
        "params = {\n",
        "    'max_depth': range(1, 11),\n",
        "    'n_estimators': range(50, 300),\n",
        "    'learning_rate': np.linspace(0.05, 0.95, 100)\n",
        "}\n",
        "n_iter = 50\n",
        "scoring = 'roc_auc'\n",
        "cv = 5\n",
        "\n",
        "gb_empl = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e12085a",
      "metadata": {
        "id": "3e12085a"
      },
      "outputs": [],
      "source": [
        "# Результат подбора гиперпараметров для gb_empl\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3cfd7ef",
      "metadata": {
        "id": "e3cfd7ef"
      },
      "outputs": [],
      "source": [
        "# Средняя продолжительность обучения gb_empl (сек.)\n",
        "\n",
        "print('{:.4f}'.format(gb_empl.cv_results_['mean_fit_time'].mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6276a504",
      "metadata": {
        "id": "6276a504"
      },
      "outputs": [],
      "source": [
        "# На тестовой выборке оцените AUC и f1 для модели gb_empl\n",
        "# Добавьте результат в empl_results\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "909b8922-b01b-4a0c-8166-a390817c76ed",
      "metadata": {
        "id": "909b8922-b01b-4a0c-8166-a390817c76ed"
      },
      "source": [
        "##### `xgb_empl` (XGBClassifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d03469d",
      "metadata": {
        "id": "5d03469d"
      },
      "outputs": [],
      "source": [
        "# Подберите оптимальные гиперпараметры обучения xgb_empl с помощью RandomizedSearchCV\n",
        "# Не забудьте зафиксировать RANDOM_STATE\n",
        "\n",
        "estimator = ...\n",
        "params = {\n",
        "    'max_depth': range(1, 11),\n",
        "    'n_estimators': range(50, 300),\n",
        "    'learning_rate': np.linspace(0.05, 0.95, 100)\n",
        "}\n",
        "n_iter = 50\n",
        "scoring = 'roc_auc'\n",
        "cv = 5\n",
        "\n",
        "xgb_empl = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f2f3879",
      "metadata": {
        "id": "5f2f3879"
      },
      "outputs": [],
      "source": [
        "# Результат подбора гиперпараметров для xgb_empl\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12dfeb17",
      "metadata": {
        "id": "12dfeb17"
      },
      "outputs": [],
      "source": [
        "# Средняя продолжительность обучения xgb_empl (сек.)\n",
        "\n",
        "print('{:.4f}'.format(xgb_empl.cv_results_['mean_fit_time'].mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8df3cceb",
      "metadata": {
        "id": "8df3cceb"
      },
      "outputs": [],
      "source": [
        "# На тестовой выборке оцените AUC и f1 для модели xgb_empl\n",
        "# Добавьте результат в empl_results\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8befcb1d-3d5c-451c-bc1b-5c16fc406e64",
      "metadata": {
        "id": "8befcb1d-3d5c-451c-bc1b-5c16fc406e64"
      },
      "source": [
        "##### `lgbm_empl` (LGBMClassifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c64536d5",
      "metadata": {
        "id": "c64536d5"
      },
      "outputs": [],
      "source": [
        "# Подберите оптимальные гиперпараметры обучения lgbm_empl с помощью RandomizedSearchCV\n",
        "# Не забудьте зафиксировать RANDOM_STATE\n",
        "\n",
        "estimator = ... # verbose=-1\n",
        "params = {\n",
        "    'max_depth': range(1, 11),\n",
        "    'n_estimators': range(50, 300),\n",
        "    'learning_rate': np.linspace(0.05, 0.95, 100)\n",
        "}\n",
        "n_iter = 50\n",
        "scoring = 'roc_auc'\n",
        "cv = 5\n",
        "\n",
        "lgbm_empl = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "530074eb",
      "metadata": {
        "id": "530074eb"
      },
      "outputs": [],
      "source": [
        "# Результат подбора гиперпараметров для lgbm_empl\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "426ee6b5",
      "metadata": {
        "id": "426ee6b5"
      },
      "outputs": [],
      "source": [
        "# Средняя продолжительность обучения lgbm_empl (сек.)\n",
        "\n",
        "print('{:.4f}'.format(lgbm_empl.cv_results_['mean_fit_time'].mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "808881fe",
      "metadata": {
        "id": "808881fe"
      },
      "outputs": [],
      "source": [
        "# На тестовой выборке оцените AUC и f1 для модели lgbm_empl\n",
        "# Добавьте результат в empl_results\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfd0f161-7dad-4ac9-a515-20842390775a",
      "metadata": {
        "id": "cfd0f161-7dad-4ac9-a515-20842390775a"
      },
      "source": [
        "##### `catb_empl` (CatBoostClassifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b44dec9a",
      "metadata": {
        "id": "b44dec9a"
      },
      "outputs": [],
      "source": [
        "# Подберите оптимальные гиперпараметры обучения catb_empl с помощью RandomizedSearchCV\n",
        "# Не забудьте зафиксировать RANDOM_STATE\n",
        "\n",
        "estimator = CatBoostClassifier(random_state=RANDOM_STATE, verbose=False, cat_features=...)\n",
        "params = {\n",
        "    'max_depth': range(1, 11),\n",
        "    'n_estimators': range(50, 300),\n",
        "    'learning_rate': np.linspace(0.05, 0.95, 100)\n",
        "}\n",
        "n_iter = 50\n",
        "scoring = 'roc_auc'\n",
        "cv = 5\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "554e736d",
      "metadata": {
        "id": "554e736d"
      },
      "outputs": [],
      "source": [
        "# Результат подбора гиперпараметров для catb_empl\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5177f832",
      "metadata": {
        "id": "5177f832"
      },
      "outputs": [],
      "source": [
        "# Средняя продолжительность обучения catb_empl (сек.)\n",
        "\n",
        "print('{:.4f}'.format(catb_empl.cv_results_['mean_fit_time'].mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7de296d",
      "metadata": {
        "id": "e7de296d"
      },
      "outputs": [],
      "source": [
        "# На тестовой выборке оцените AUC и f1 для модели catb_empl\n",
        "# Добавьте результат в empl_results\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25b56408",
      "metadata": {
        "id": "25b56408"
      },
      "source": [
        "##### Сравнение моделей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57d86d60",
      "metadata": {
        "id": "57d86d60"
      },
      "outputs": [],
      "source": [
        "# Сравните качество прогноза моделей на тестовых выборках\n",
        "\n",
        "empl_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "648ca513",
      "metadata": {
        "id": "648ca513"
      },
      "outputs": [],
      "source": [
        "# Визуализируйте качество прогноза моделей, построив график f1 ~ AUC\n",
        "\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.title('Точность прогноза моделей на тестовой выборке')\n",
        "ax = sns.scatterplot(data=empl_results, x=..., y=..., hue='model', s=150)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25877cfe",
      "metadata": {
        "id": "25877cfe"
      },
      "source": [
        "### **Early Stopping**\n",
        "\n",
        "Ранняя остановка (Early Stopping) — это универсальный и широко распространённый метод регуляризации, который позволяет эффективно предотвращать переобучение моделей. Суть метода заключается в остановке обучения модели до завершения всех запланированных итераций в случае, если прогнозные способности модели на валидационной выборке перестают улучшаться или начинают ухудшаться.\n",
        "\n",
        "**Основные принципы:**\n",
        "\n",
        "* Исходная выборка делится на подвыборки:\n",
        "\n",
        "    * Обучающая выборка (train).\n",
        "\n",
        "    * Валидационная выборка (validation) — на ней оценивается качество модели **во время обучения**.\n",
        "\n",
        "    * Тестовая выборка (test) — используется для финальной оценки модели (не участвует в процессе обучения).\n",
        "\n",
        "* Мониторинг метрики. Если в процессе обучения метрика не улучшается в течение заданного числа итераций, обучение останавливается (прекращается).\n",
        "\n",
        "* Сохранение лучшей модели. Во время обучения сохраняются веса модели на той итерации, когда валидационная метрика была наилучшей."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94ef9c73",
      "metadata": {
        "id": "94ef9c73"
      },
      "source": [
        "### **Вероятностные методы оптимизации гиперпараметров**\n",
        "\n",
        "Вероятностные методы оптимизации гиперпараметров — это итерационные методы, которые позволяют находить оптимальные гиперпараметры обучения моделей быстрее и точнее, чем Grid Search и Randomized Search, за счет использования вероятностной модели целевой функции.\n",
        "\n",
        "На каждой итерации метод оценивает, в какой следующей точке с наибольшей вероятностью будет достигнуто улучшение текущей оценки оптимума. Вероятностные методы особенно полезны при работе со сложными многомерными пространствами гиперпараметров.\n",
        "\n",
        "**Преимущества вероятностных методов перед Grid Search и Randomized Search:**\n",
        "\n",
        "* Каждая итерация использует информацию, полученную на предыдущих итерациях.\n",
        "\n",
        "* Вероятностные методы способны моделировать внутренние зависимости между гиперпараметрами.\n",
        "\n",
        "* Вероятностные методы позволяют достичь более высокого качества, если было выполнено достаточное количество итераций.\n",
        "\n",
        "* Гибкость. Вероятностные методы способны работать с непрерывными, дискретными и категориальными параметрами.\n",
        "\n",
        "**Основным недостатком** вероятностных методов является высокая вычислительная сложность по сравнению с Grid Search и Randomized Search.\n",
        "\n",
        "Одним из основных вероятностных методов является TPE (Tree-structured Parzen Estimator). TPE реализован в двух наиболее популярных библиотеках для оптимизации гиперпараметров: Optuna и Hyperopt.\n",
        "\n",
        "Подробнее можно изучить по **ссылкам:**\n",
        "\n",
        "* [Подбор гиперпараметров | education.yandex.ru](https://education.yandex.ru/handbook/ml/article/podbor-giperparametrov).\n",
        "\n",
        "* [Optuna vs Hyperopt: Which Hyperparameter Optimization Library Should You Choose? | eptun.ai](https://neptune.ai/blog/optuna-vs-hyperopt)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7931690d",
      "metadata": {
        "id": "7931690d"
      },
      "source": [
        "### **Датасет *Predict Students' Dropout and Academic Success***\n",
        "\n",
        "**Для решения задания 3 рассмотрим датасет [Predict Students' Dropout and Academic Success](https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success).**\n",
        "\n",
        "**ВНИМАНИЕ:** При решении задания **используйте файл students.csv** из приложения к ноутбуку, поскольку исходный датасет был изменен авторами курса.\n",
        "\n",
        "Датасет создан на основе информации из Португальского высшего учебного заведения и содержит информацию о студентах, зачисленных на различные программы бакалавриата: агрономия, дизайн, педагогика и др. Цель датасета — на ранних этапах обучения выявить студентов, находящихся в зоне риска для последующего оказания поддержки. Набор данных включает информацию, известную на момент зачисления студентов (академическая история, демографические и социально-экономические факторы), а также их академическую успеваемость по итогам первого и второго семестров.\n",
        "\n",
        "Датасет предназначен для решения задачи **многоклассовой классификации**.\n",
        "\n",
        "Целевая переменная — Target:\n",
        "\n",
        "* Dropout — студент отчислен.\n",
        "\n",
        "* Enrolled — студент продолжает обучение.\n",
        "\n",
        "* Graduate — студент успешно завершил обучение.\n",
        "\n",
        "Датасет содержит большое количество категориальных признаков, а в целевой переменной присутствует дисбаланс классов."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5efec7f3",
      "metadata": {
        "id": "5efec7f3"
      },
      "source": [
        "### ***Задание 3***\n",
        "\n",
        "Выполните предобработку датасета (см. код).\n",
        "\n",
        "Обучите модель `catb_stud_def` (CatBoostClassifier) c параметрами `catb_stud_def_params` (для обучения используйте `X_stud_sample_train`).\n",
        "\n",
        "Обучите модель `catb_stud_es` (CatBoostClassifier) с использованием early stopping ([early_stopping_rounds](https://catboost.ai/docs/en/references/training-parameters/overfitting-detection#early_stopping_rounds) и параметрами `catb_stud_es_params`. Критерий остановки — 50 итераций без увеличения accuracy на валидационной выборке `X_stud_sample_val` (для обучения используйте `X_stud_sample_train`).\n",
        "\n",
        "Выполните оптимизацию гиперпараметров обучения CatBoostClassifier с помощью optuna. Для этого необходимо определить целевую функцию optuna (objective) **с использованием стратифицированной кросс-валидации ([StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html)) и ранней остановки на каждом фолде кросс-валидации** (критерий остановки не фиксируется на одном значении и является оптимизируемым гиперпараметром). Метрика оптимизации гиперпараметров — среднее значение **accuracy** на валидации по результатам кросс-валидации.\n",
        "\n",
        "На оптимальном наборе признаков и всей обучающей выборке обучите модель `catb_stud` (CatBoostClassifier).\n",
        "\n",
        "На тестовой выборке постройте отчёт по метрикам классификации для моделей `catb_stud_def`, `catb_stud_es` и `catb_stud`.\n",
        "\n",
        "*На практике количество итераций при оптимизации гиперпараметров с помощью optuna или hyperopt зависит от сложности модели и размера датасета. **Для реальных задач 50 итераций, вероятнее всего, будет недостаточно**. В рамках данного задания небольшое число итераций используется для экономии времени.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "041e4df7",
      "metadata": {
        "id": "041e4df7"
      },
      "outputs": [],
      "source": [
        "# Считайте набор данных\n",
        "\n",
        "df_stud = pd.read_csv('students.csv')\n",
        "df_stud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9bf9951",
      "metadata": {
        "id": "b9bf9951"
      },
      "outputs": [],
      "source": [
        "# В датасете присутствует дисбаланс классов\n",
        "\n",
        "df_stud['Target'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1de724a",
      "metadata": {
        "id": "f1de724a"
      },
      "outputs": [],
      "source": [
        "# Все категориальные признаки описаны числами\n",
        "\n",
        "df_stud.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee80423a",
      "metadata": {
        "id": "ee80423a"
      },
      "outputs": [],
      "source": [
        "# Количество уникальных значений в каждом из столбцов датасета\n",
        "\n",
        "df_stud.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b113153",
      "metadata": {
        "id": "2b113153"
      },
      "outputs": [],
      "source": [
        "# Создайте список категориальных переменных (не включая целевую переменную)\n",
        "\n",
        "stud_cat_feat = ['Marital status', 'Application mode', 'Course', 'Daytime/evening attendance', 'Previous qualification',\n",
        "                   'Nationality', \"Mother's qualification\", \"Father's qualification\", 'Displaced', 'Educational special needs',\n",
        "                   'Debtor', 'Tuition fees up to date', 'Gender', 'Scholarship holder', 'International']\n",
        "stud_cat_feat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "737b1ca9",
      "metadata": {
        "id": "737b1ca9"
      },
      "outputs": [],
      "source": [
        "# Выделите объясняемый фактор в отдельную переменную\n",
        "\n",
        "X_stud, y_stud = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d52a4d8",
      "metadata": {
        "id": "2d52a4d8"
      },
      "outputs": [],
      "source": [
        "# Разделите датасет на обучающую (50%) и тестовую (50%) выборки со стратификацией по целевой переменной\n",
        "# Не забудьте зафиксировать RANDOM_STATE\n",
        "\n",
        "X_stud_train, X_stud_test, y_stud_train, y_stud_test = ... # 50/50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8ec444f",
      "metadata": {
        "id": "a8ec444f"
      },
      "outputs": [],
      "source": [
        "# Разделите обучающую выборку (train) на две подвыборки со стратификацией по целевой переменной (по y_stud_train):\n",
        "#   1. sample_train (75% от train) — для обучения модели\n",
        "#   2. sample_val (25% от train) — для валидации модели в процессе обучения\n",
        "# Не забудьте зафиксировать RANDOM_STATE\n",
        "\n",
        "X_stud_sample_train, X_stud_sample_val, y_stud_sample_train, y_stud_sample_val = ... # 75/25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de382368",
      "metadata": {
        "id": "de382368"
      },
      "outputs": [],
      "source": [
        "# Обучите модель catb_stud_def\n",
        "# Для обучения используйте sample_train, sample_val также укажите для визуализации обучения\n",
        "\n",
        "catb_stud_def_params = {\n",
        "    'cat_features': stud_cat_feat,\n",
        "    'eval_metric': 'Accuracy', # Метрика для оценки качества на валидации (при early stopping)\n",
        "    'random_state': RANDOM_STATE,\n",
        "    'verbose': False\n",
        "}\n",
        "\n",
        "catb_stud_def = CatBoostClassifier(...).fit(..., eval_set=(...))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7334fb58",
      "metadata": {
        "id": "7334fb58"
      },
      "outputs": [],
      "source": [
        "# Визуализируйте изменение ошибки и accuracy в процессе обучения catb_stud_def\n",
        "\n",
        "catb_stud_def_evals_result = catb_stud_def.get_evals_result()\n",
        "\n",
        "fig, ax = plt.subplots(2, 1, figsize=(12, 10))\n",
        "\n",
        "ax[0].plot(catb_stud_def_evals_result['learn']['MultiClass'], label='train', color='blue')\n",
        "ax[0].plot(catb_stud_def_evals_result['validation']['MultiClass'], label='val', color='green')\n",
        "ax[0].set_xlabel('Iterations')\n",
        "ax[0].set_ylabel('MultiClass')\n",
        "ax[0].legend()\n",
        "ax[0].grid()\n",
        "\n",
        "ax[1].plot(catb_stud_def_evals_result['learn']['Accuracy'], label='train', color='blue')\n",
        "ax[1].plot(catb_stud_def_evals_result['validation']['Accuracy'], label='val', color='green')\n",
        "ax[1].set_xlabel('Iterations')\n",
        "ax[1].set_ylabel('Accuracy')\n",
        "ax[1].legend()\n",
        "ax[1].grid()\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f593951b",
      "metadata": {
        "id": "f593951b"
      },
      "outputs": [],
      "source": [
        "# Постройте отчёт по метрикам классификации для модели catb_stud_def на тестовой выборке\n",
        "\n",
        "print(classification_report(..., digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3440c1bc",
      "metadata": {
        "id": "3440c1bc"
      },
      "outputs": [],
      "source": [
        "# Обучите модель catb_stud_es c ранней остановкой после 50 итераций\n",
        "# Для обучения и валидации используйте sample_train и sample_val\n",
        "\n",
        "catb_stud_es_params = {\n",
        "    'cat_features': ...,\n",
        "    'eval_metric': 'Accuracy',\n",
        "    'random_state': RANDOM_STATE,\n",
        "    'verbose': False\n",
        "}\n",
        "\n",
        "catb_stud_es = CatBoostClassifier(...).fit(..., eval_set=(...), early_stopping_rounds=...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77f785c4",
      "metadata": {
        "id": "77f785c4"
      },
      "outputs": [],
      "source": [
        "# Визуализируйте изменение ошибки и accuracy в процессе обучения catb_stud_es\n",
        "\n",
        "catb_stud_es_evals_result = ...\n",
        "\n",
        "fig, ax = plt.subplots(2, 1, figsize=(12, 10))\n",
        "\n",
        "ax[0].plot(catb_stud_es_evals_result['learn']['MultiClass'], label='train', color='blue')\n",
        "ax[0].plot(catb_stud_es_evals_result['validation']['MultiClass'], label='val', color='green')\n",
        "ax[0].set_xlabel('Iterations')\n",
        "ax[0].set_ylabel('MultiClass')\n",
        "ax[0].legend()\n",
        "ax[0].grid()\n",
        "\n",
        "ax[1].plot(catb_stud_es_evals_result['learn']['Accuracy'], label='train', color='blue')\n",
        "ax[1].plot(catb_stud_es_evals_result['validation']['Accuracy'], label='val', color='green')\n",
        "ax[1].set_xlabel('Iterations')\n",
        "ax[1].set_ylabel('Accuracy')\n",
        "ax[1].legend()\n",
        "ax[1].grid()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "991bda9f",
      "metadata": {
        "id": "991bda9f"
      },
      "outputs": [],
      "source": [
        "# Постройте отчёт по метрикам классификации для модели catb_stud_es на тестовой выборке\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "234e17be",
      "metadata": {
        "id": "234e17be"
      },
      "outputs": [],
      "source": [
        "# Определите целевую функцию objective для оптимизации параметров с помощью optuna\n",
        "# Не забудьте фиксировать random_state, где это возможно\n",
        "\n",
        "def objective(trial, X, y, cat_features, cv=4, random_state=None):\n",
        "    \"\"\"\n",
        "    Целевая функция для оптимизации гиперпараметров CatBoostClassifier с помощью optuna.\n",
        "\n",
        "    Аргументы:\n",
        "        trial (optuna.trial.Trial): Объект trial для предложения гиперпараметров.\n",
        "        X (pandas.DataFrame): Таблица с признаками.\n",
        "        y (array-like): Массив значений целевой переменной.\n",
        "        cat_features (list[str]): Список с категориальными признаками.\n",
        "        cv (int): Количество фолдов для стратифицированной кросс-валидации. По умолчанию — 5.\n",
        "        random_state : (int|None): Сид для фиксирования случайного состояния. По умолчанию — None (не фиксировать).\n",
        "    \"\"\"\n",
        "    params = {\n",
        "    'learning_rate': trial.suggest_float('learning_rate', 0.05, 1, log=True), # Темп обучения: float между 0.05 и 1 в логарифмическом масштабе\n",
        "    'max_depth': trial.suggest_int('max_depth', 1, 8), # Максимальная глубина деревьев: int между 1 и 8\n",
        "    'n_estimators': ..., # Количество деревьев в ансамбле: int между 100 и 800\n",
        "    'colsample_bylevel': ..., # Доля признаков, используемых для построения каждого уровня дерева: float между 0.05 и 1.0\n",
        "\n",
        "    'cat_features': ...,\n",
        "    'eval_metric': 'Accuracy',\n",
        "    'random_state': random_state,\n",
        "    'verbose': False\n",
        "    }\n",
        "\n",
        "    early_stopping_rounds = trial.suggest_int(...) # Критерий остановки: int между 20 и 100\n",
        "\n",
        "    accuracy_scores = []\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=..., shuffle=True, random_state=...)\n",
        "\n",
        "    for train_idx, val_idx in skf.split(...):\n",
        "        X_train, X_val = ...\n",
        "        y_train, y_val = ...\n",
        "        model = CatBoostClassifier(...).fit(..., eval_set=(...), ...)\n",
        "        accuracy_scores.append(...) # val\n",
        "\n",
        "    return np.mean(accuracy_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49925235",
      "metadata": {
        "id": "49925235"
      },
      "outputs": [],
      "source": [
        "# Оптимизируйте гиперпараметры модели с помощью optuna (sampler — TPESampler)\n",
        "# Для подбора гиперпараметров используйте train\n",
        "# Не забудьте зафиксировать RANDOM_STATE (в seed TPESampler)\n",
        "\n",
        "n_trials = 60 # Количество тестируемых комбинаций параметров\n",
        "cv = 4 # Количество фолдов при кросс-валидации\n",
        "\n",
        "stud_sampler = TPESampler(seed=RANDOM_STATE)\n",
        "\n",
        "stud_study = optuna.create_study(\n",
        "    direction='maximize', # Максимизация accuracy\n",
        "    sampler=stud_sampler,\n",
        "    study_name='CatBoostClassifier'\n",
        ")\n",
        "\n",
        "stud_study.optimize(lambda trial: objective(trial, X_stud_train, y_stud_train, cat_features=stud_cat_feat, cv=..., random_state=...),\n",
        "    n_trials=...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0da5d5a",
      "metadata": {
        "id": "d0da5d5a"
      },
      "outputs": [],
      "source": [
        "# Визуализируйте важность гиперпараметров обучения после оптимизации\n",
        "\n",
        "param_importance = get_param_importances(stud_study)\n",
        "\n",
        "plt.bar(..., ...)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de3e11cf",
      "metadata": {
        "id": "de3e11cf"
      },
      "outputs": [],
      "source": [
        "# Выведете оптимальные гиперпараметры\n",
        "\n",
        "stud_study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "660a8641",
      "metadata": {
        "id": "660a8641"
      },
      "outputs": [],
      "source": [
        "# Обучите модель catb_stud c оптимальными гиперпараметрами\n",
        "# Для обучения и валидации используйте sample_train и sample_val\n",
        "\n",
        "catb_stud_params = {\n",
        "    'cat_features': stud_cat_feat,\n",
        "    'eval_metric': 'Accuracy',\n",
        "    'random_state': RANDOM_STATE,\n",
        "    'verbose': False\n",
        "}\n",
        "\n",
        "catb_stud = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "861c664f",
      "metadata": {
        "id": "861c664f"
      },
      "outputs": [],
      "source": [
        "# Постройте отчёт по метрикам классификации для модели catb_stud на тестовой выборке\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c4a69d4",
      "metadata": {
        "id": "6c4a69d4"
      },
      "outputs": [],
      "source": [
        "# Определите наиболее влиятельный признак в модели catb_stud\n",
        "\n",
        "stud_importance = pd.DataFrame({\n",
        "    'feat_name': catb_stud.feature_names_,\n",
        "    'feat_importance': catb_stud.get_feature_importance(),\n",
        "})\n",
        "\n",
        "stud_importance.sort_values(by=['feat_importance'], ascending=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "ml-course",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}